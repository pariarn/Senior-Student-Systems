{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and save the hitting time matrices for brain networks for all the subjects:\n",
    "\n",
    "This code runs on fMRI BOLD measurments from UCLA study. \n",
    "- Input the task setting and the atlas to be used for graph representation\n",
    "- The data has already been de-faced and in MNI spapce\n",
    "Steps:\n",
    "1. Get rid of the motion paramaters for every voxel\n",
    "2. Map the data to regions specified by the atlas (reducing the dimensionality of fMRI to the number of ROIs)\n",
    "3. Calculate the similarity matrix to be partial correlations\n",
    "4. Threshold the similarity matrix to remove weaker connections\n",
    "5. Build the graph by calculating the adjacency matrix\n",
    "6. Find the mean first passage time between every 2 nodes in the graph and save it as the hitting time matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing Jupyter command 'nbconvert': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert sharedPaul.ipynb --to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### inputs ###\n",
    "task = \"rest\" # rest or bart\n",
    "atLas = \"mmp\" # msdl or haox or mmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMapsMasker\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import nibabel as nib\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "correlation_measure = ConnectivityMeasure(kind='partial correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## reading the subject's ID's and groups\n",
    "wb = openpyxl.load_workbook('Subjects1.xlsx')\n",
    "wb.get_sheet_names()\n",
    "sheet = wb.get_sheet_by_name('Sheet1')\n",
    "N = sheet.max_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory to raw fMRI measurements\n",
    "Data_DIR = \"F://UCLA//func/\"\n",
    "os.chdir(Data_DIR)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# motCor function to correct for motion\n",
    "# inputs: subject ID and task\n",
    "# output: data confounds containing the motion regressors\n",
    "def motCor(sub, task):\n",
    "    # recovering file name from subject ID and task\n",
    "    Data_Name = \"sub-\" + sub + \"_task-\" + task + \"_bold_space-MNI152NLin2009cAsym_preproc\"    \n",
    "    # set the name of the desired data set here:\n",
    "    fmri_filenames = Data_Name + \"_filt.nii.gz\"\n",
    "    # the file containing motion parameters\n",
    "    tsv_file = \"sub-\" + sub+ \"_task-\" + task + \"_bold_confounds.tsv\" \n",
    "    df = pd.read_table(tsv_file, sep='\\t', header=0) \n",
    "    [dim1, dim2] = np.shape(df)\n",
    "    # identify which motion parameters to use\n",
    "    conf_clmns = [row for row in df if row == \"WhiteMatter\" or row == \"X\" or row == \"Y\" or row == \"Z\"]\n",
    "    data_confs = np.zeros((dim1, 4))\n",
    "    cntr = 0\n",
    "    for item in conf_clmns:\n",
    "        data_confs[:, cntr] = np.array(df[item])\n",
    "        cntr = cntr + 1\n",
    "    # removing the first 10 seconds of fMRI (the sharp transition part of fMRI)\n",
    "    data_confs = data_confs[5:,:]\n",
    "    return data_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensionality reduction function maps the fMRI data on MMP-HCP atlas with 180 regions\n",
    "# inputs: subject ID and task and motion confounds\n",
    "# output: the time series corresponding to 180 regions of MMP-HCP (Glasser-2016) atlas\n",
    "def dimRed(sub, task, confounds):\n",
    "    # recovering file name from subject ID and task\n",
    "    Data_Name = \"sub-\" + sub + \"_task-\" + task + \"_bold_space-MNI152NLin2009cAsym_preproc\"\n",
    "    # file containing the 180 ROIs map\n",
    "    atlas_filename = \"MMP1_rois.nii\"\n",
    "    \n",
    "    masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True,\n",
    "                               memory='nilearn_cache', verbose=5) \n",
    "    \n",
    "    # set the name of the desired data set here:\n",
    "    fmri_filenames = Data_Name + \"_filt.nii.gz\"\n",
    "    time_series = masker.fit_transform(filenames, confounds = data_confs)\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finding the adjacency matrix: threshold the fMRI time series and map it to a graph with 180 nodes and \n",
    "# inputs: correlation (partial correlation) matrix and the desired percentile to be used to find the threshold\n",
    "# output: adjacency matrix\n",
    "def adjMatrix(C_matrix, percentile):\n",
    "    # find the magnitude of the correlations\n",
    "    A_matrix = abs(C_matrix)\n",
    "    A_vec = np.reshape(A_matrix, (1, 180*180))\n",
    "    \n",
    "    # remove the self loops\n",
    "    np.fill_diagonal(A_matrix, 0)\n",
    "    \n",
    "    # calculate the threshold from desired percentile\n",
    "    thrshld = np.percentile(A_vec, 30)\n",
    "    L = np.size(A_matrix,axis = 0)\n",
    "    \n",
    "    # threshold the adjacency matrix\n",
    "    A_matrix = np.array(A_matrix)\n",
    "    low_values_flags = A_matrix < thrshld\n",
    "    A_matrix[low_values_flags] = 0\n",
    "    return A_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculating mean first passage time of the random walk (also known as hitting time) from the normalized Laplacian\n",
    "# input: adjacency matrix\n",
    "# output: hitting time matrix\n",
    "def meanfstpsg(A_matrix):\n",
    "    L = np.size(A_matrix,axis = 0)\n",
    "    \n",
    "    D_matrix = np.zeros((L,L)) \n",
    "    D_inv = np.zeros((L,L)) \n",
    "    D_sqrt = np.zeros((L,L)) \n",
    "    D_sqrt_inv = np.zeros((L,L)) \n",
    "    for i in range(L):\n",
    "        D_matrix[i,i] = np.sum(A_matrix[i]) # degree matrix\n",
    "        D_inv[i,i] = 1./D_matrix[i,i] # inverse of degree matrix\n",
    "        D_sqrt[i,i] = np.sqrt(D_matrix[i,i]) # second root of degrees\n",
    "        D_sqrt_inv[i,i] = 1./D_sqrt[i,i] # inverse of the second roots of degrees \n",
    "    \n",
    "    # the probability transitioning matrix: P = A/D\n",
    "    p_matrix = np.dot(D_inv, A_matrix)\n",
    "    \n",
    "    # normalized graph Laplacian\n",
    "    eye_matrix = np.eye(L,L)\n",
    "    eye_P = eye_matrix - p_matrix\n",
    "\n",
    "    G_Lap = np.dot(D_sqrt,eye_P)\n",
    "    G_Lap_n = np.dot(G_Lap, D_sqrt_inv)\n",
    "    \n",
    "    # eigen decomposition of the graph Laplacian\n",
    "    [eig_val, eig_vec] = np.linalg.eigh(G_Lap_n)\n",
    "    \n",
    "    # calculate the eigen matrix for hitting time calculations - to reduce the computation time\n",
    "    eig_matrix = [] # the columns of the matrix are the eigenvectors divided by the corresponding eigenvalue\n",
    "    for k in range(1, L): # the first eigenvalue is zero\n",
    "        eigmatrix.append(np.divide(eig_vec, math.sqrt(eig_val[k])), 1)\n",
    "    \n",
    "    # calculating the hitting times\n",
    "    H = np.zeros((L,L))\n",
    "    d = np.sum(D_matrix)\n",
    "    for i in range(L):\n",
    "        deg_i = D_matrix[i,i]\n",
    "        t_1 = (d/d_i)*(eigmatrix[i,:]*np.transpose(eigmatrix[i,:]))\n",
    "        for j in range(L):\n",
    "            deg_j = D_matrix[j,j]\n",
    "            t_2 = (d/(d_i*d_j))*(eigmatrix[j,:]*np.transpose(eigmatrix[i,:]))\n",
    "            H[i,j] = t_1 - t_2\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## calculating and saving hitting-time matrix for every subject\n",
    "for i in range(1,N):\n",
    "    # subject ID:\n",
    "    ID = sheet.cell(row=i+1, column=1).value\n",
    "    sub = str(ID) \n",
    "    # motion regressors:\n",
    "    data_confs = motCor(sub, task)\n",
    "    # time series for 180 ROIs:\n",
    "    time_series = dimRed(sub, task, data_confs)\n",
    "    # similarity matrix:\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]  \n",
    "    # adjacency matrix\n",
    "    A_matrix = adjMatrix(correlation_matrix, percentile = 30)\n",
    "    # hitting time matrix:\n",
    "    H = meanfstpsg(A_matrix)\n",
    "    \n",
    "    np.savetxt(\"hit_time_task_\" + atLas + \"_sub_data_7p_filt_\" + Data_Name, H, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
